{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import fastText\n",
    "from utils import *\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_en = np.load('data/snips_processed/USE-en.npy')\n",
    "use_en = np.squeeze(use_en, axis=1)\n",
    "labs = np.load('data/snips_processed/labs.npy')\n",
    "\n",
    "\n",
    "dataset, lab2id, id2lab =import_data('data/snips_processed/snips.csv')\n",
    "sents = dataset[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sv_model = fastText.load_model('data/cc.sv.300.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_m(sentence, model, max_len):\n",
    "    result = []\n",
    "    words = ['sossos'] + sentence.split() + ['eoseos']\n",
    "    \n",
    "    for word in words:\n",
    "        result.append(model.get_word_vector(word))\n",
    "    \n",
    "\n",
    "    if len(words) < max_len:\n",
    "        result.extend([np.zeros(300)] * (max_len  -  len(words)))\n",
    "    return np.array(result)\n",
    "    \n",
    "    \n",
    "def prepare_sentences(sents, preprocess=False):       \n",
    "    sents = pre_process_text(sents)  if preprocess else sents\n",
    "    lens = list(map(lambda x: x.count(' ') + 3, sents))\n",
    "    max_len = max(lens)\n",
    "    m = np.stack(list(map(lambda x:sentence_m(x, sv_model, max_len), sents)))\n",
    "    return m, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_lens = prepare_sentences(sents, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Код Архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sys.exit()\n",
    "\n",
    "filter_sizes = [2,3,5]\n",
    "num_filters = 512\n",
    "drop = 0.3\n",
    "\n",
    "inputs = Input(shape=(MAX_LEN,), dtype='int32')\n",
    "embedding = Embedding(input_dim=len(word_index) + 1, # dict size\n",
    "                      output_dim=EMB_DIM, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=MAX_LEN, # number of words at one batch\n",
    "                      trainable=False)(inputs)\n",
    "\n",
    "reshape = Reshape((MAX_LEN,EMB_DIM,1))(embedding)  #words*embedding matrix\n",
    "\n",
    "# 512 filters that takes 2-5 words with all embedding numbers and output single value.\n",
    "# 2d -> 1d because emb dim in kernel size + dimention on number  of filters. Single filter outputs MAX_LEN - filter_sizes[0] + 1 values\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMB_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMB_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMB_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "#gets single value for each filter. 512 values total for each pool. Why strides?\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_LEN - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "lstm_1 = Bidirectional(LSTM(256, dropout=0.5, recurrent_dropout=0.5))(embedding) # it was 300 units\n",
    "flatten_lstm = Reshape((1, 1, 512))(lstm_1)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, \n",
    "                                           flatten_lstm])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, max_s_len , emb_dim = 300 , out_size = 7):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #(batch, sent_len, emb_dim)\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_size =out_size\n",
    "        self.max_s_len = max_s_len\n",
    "        self.kernel_sizes = [2,3,5]\n",
    "\n",
    "        self.max_pool_kernel_size = [(self.max_s_len - x + 1, 1) for x in self.kernel_sizes]\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(self.kernel_sizes[0], self.emb_dim), )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # add chanels dimention:\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x1 = F.max_pool2d(F.relu(x1), self.max_pool_kernel_size[0])\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = ConvNet(19)\n",
    "\n",
    "t = torch.tensor(a).float()\n",
    "out  = cn.forward(t)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLstmNet(nn.Module):\n",
    "    def __init__(self, max_s_len , emb_dim = 300 , out_size = 7):\n",
    "        super(BiLstmNet, self).__init__()\n",
    "        \n",
    "        #(batch, sent_len, emb_dim)\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_size =out_size\n",
    "        self.max_s_len = max_s_len\n",
    "        \n",
    "        #dont add dropout  to last layer since there is only one layer\n",
    "        self.lstm = nn.LSTM(input_size = self.emb_dim, hidden_size = 256,\n",
    "                         batch_first=True, bidirectional=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, lens):\n",
    "        ps = nn.utils.rnn.pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        out, (h,c) = self.lstm(ps)\n",
    "        \n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([109, 512]),\n",
       " torch.Size([2, 10, 256]),\n",
       " tensor(0.0159, grad_fn=<SelectBackward>),\n",
       " tensor(0.0121, grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bln =  BiLstmNet(19)\n",
    "out, h = bln(t, lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, max_s_len , emb_dim = 300, out_size = 512):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        #(batch, sent_len, emb_dim)\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_size =out_size\n",
    "        self.max_s_len = max_s_len\n",
    "        self.kernel_sizes = [2,3,5]\n",
    "        self.cnn_chan  = 128\n",
    "        self.lstm_hid  = 256\n",
    "\n",
    "        self.max_pool_kernel_size = [(self.max_s_len - x + 1, 1) for x in self.kernel_sizes]\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.cnn_chan, kernel_size=(self.kernel_sizes[0], self.emb_dim), )\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=self.cnn_chan, kernel_size=(self.kernel_sizes[1], self.emb_dim), )\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=self.cnn_chan, kernel_size=(self.kernel_sizes[2], self.emb_dim), )\n",
    "        \n",
    "        #dont add dropout  to last layer since there is only one layer\n",
    "        self.lstm = nn.LSTM(input_size = self.emb_dim, hidden_size = self.lstm_hid,\n",
    "                         batch_first=True, bidirectional=True)\n",
    "    \n",
    "        self.lin = nn.Linear(self.lstm_hid*2 + self.cnn_chan * 3, out_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, lens):\n",
    "        \n",
    "        # add chanels dimention:\n",
    "        xc = x.unsqueeze(1)\n",
    "        \n",
    "        x1 = self.conv1(xc)\n",
    "        x1 = F.max_pool2d(F.relu(x1), self.max_pool_kernel_size[0])\n",
    "        x1 = x1.squeeze(3).squeeze(2)\n",
    "        \n",
    "        x2 = self.conv1(xc)\n",
    "        x2 = F.max_pool2d(F.relu(x2), self.max_pool_kernel_size[1])\n",
    "        x2 = x2.squeeze(3).squeeze(2)\n",
    "\n",
    "        x3 = self.conv1(xc)\n",
    "        x3 = F.max_pool2d(F.relu(x3), self.max_pool_kernel_size[2])\n",
    "        x3 = x3.squeeze(3).squeeze(2)\n",
    "\n",
    "        ps = nn.utils.rnn.pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        _, (h,c) = self.lstm(ps)\n",
    "        lstm_out = torch.cat((h[1],h[0]), dim =1)\n",
    "\n",
    "        out = torch.cat((x1,x2,x3, lstm_out), dim=1)\n",
    "        \n",
    "        out = self.lin(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 19, 300), torch.Size([10, 512]), 13784)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, lens = prepare_sentences(sents[:10], True)\n",
    "\n",
    "net = RNN(19)\n",
    "out = net(t, lens)\n",
    "a.shape, out.shape, len(use_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_index(request, dots, forbiden_index=-1):\n",
    "    dists = np.linalg.norm(dots-request, axis=1)\n",
    "    res =  np.argmin(dists)\n",
    "    \n",
    "    if res == forbiden_index:\n",
    "        dists[res] = np.inf\n",
    "        return np.argmin(dists)\n",
    "    return res\n",
    "\n",
    "\n",
    "def train(model, data_in, lens, expected_out, criterion, optimizer):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # vectors = torch.tensor(vectors).float()\n",
    "    # labels = torch.tensor(labels)\n",
    "\n",
    "    model_out = model.forward(data_in, lens)\n",
    "    loss += criterion(model_out, expected_out)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / len(expected_out)\n",
    "    \n",
    "def evaluate(model, data_in, lens, labs, expected_out, criterion):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model_out = model.forward(data_in, lens)\n",
    "        right = 0\n",
    "        \n",
    "        for i  in range(len(model_out)):\n",
    "            predicted_use = model_out[i]\n",
    "            true_lab = labs[i]\n",
    "        \n",
    "            predicted_index = closest_index(predicted_use, expected_out, forbiden_index=i)\n",
    "            predicted_lab = labs[predicted_index]\n",
    "            \n",
    "            if predicted_lab == true_lab:\n",
    "                right += 1\n",
    "            \n",
    "        loss = criterion(model_out, expected_out)\n",
    "        return loss.item(), right/len(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train_model(train_data, train_out, test_data, test_out, lens, test_lens, test_labs, verbose = False, runs = 20):\n",
    "    max_s_len = train_data.shape[1]\n",
    "    net = RNN(max_s_len = max_s_len)\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    \n",
    "    data_in = torch.tensor(train_data).float()\n",
    "    data_in_t = torch.tensor(test_data).float()\n",
    "    ex_out = torch.tensor(train_out).float()\n",
    "    ex_out_t = torch.tensor(test_out).float()\n",
    "        \n",
    "    print('matrices ready, starting training')\n",
    "    t = time.time()\n",
    "    for i in range(runs):\n",
    "        loss = train(net, data_in, lens, ex_out, criterion, optimizer,)\n",
    "        if verbose and not i% 5:\n",
    "            eval_loss, acc = evaluate(net, data_in_t, test_lens, test_labs, ex_out_t, criterion)\n",
    "            print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.4f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n",
    "    \n",
    "    eval_loss = evaluate(net, data_in_t, lens_t, ex_out_t, criterion)\n",
    "    return net, eval_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrices ready, starting training\n",
      "#  0,    24 sec. train loss: 0.0000004, eval loss: 0.0021, acc = \n",
      "#  5,   147 sec. train loss: 0.0000002, eval loss: 0.0016, acc = \n",
      "# 10,   289 sec. train loss: 0.0000002, eval loss: 0.0015, acc = \n",
      "# 15,   423 sec. train loss: 0.0000001, eval loss: 0.0014, acc = \n"
     ]
    }
   ],
   "source": [
    "train_data = data[:10000]\n",
    "test_data = data[10000:]\n",
    "\n",
    "train_out = use_en[:10000]\n",
    "test_out = use_en[10000:]\n",
    "\n",
    "train_lens = data_lens[:10000]\n",
    "test_lens = data_lens[10000:]\n",
    "\n",
    "test_labs = labs[10000:]\n",
    "\n",
    "trained_net, eval_loss, acc = \n",
    "    full_train_model(train_data, train_out, test_data, test_out, train_lens, test_lens, test_labs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0013049088884145021, 0.7036)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(trained_net,\n",
    "         torch.tensor(train_data).float(),\n",
    "         train_lens,\n",
    "         train_labs,\n",
    "         torch.tensor(train_out).float(),\n",
    "         torch.nn.MSELoss()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = labs[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
