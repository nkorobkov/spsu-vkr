{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import contractions\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open('data/snips_processed/snips.csv', 'r') as f:\n",
    "    reader = csv.reader(x.replace('\\0', '') for x in f)\n",
    "    for line in reader:\n",
    "        dataset.append(line)\n",
    "dataset = np.array(dataset)\n",
    "topics = ['BookRestaurant','GetWeather', 'SearchScreeningEvent','RateBook', 'SearchCreativeWork', 'AddToPlaylist', 'PlayMusic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "@np.vectorize\n",
    "def pre_process_text(document):\n",
    "    \n",
    "    # lower case\n",
    "    document = document.lower()\n",
    "    \n",
    "    # remove extra newlines (often might be present in really noisy text)\n",
    "    document = document.translate(document.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    \n",
    "    # remove accented characters\n",
    "    document = remove_accented_chars(document)\n",
    "    \n",
    "    # expand contractions    \n",
    "    document = expand_contractions(document)\n",
    "               \n",
    "    # remove special characters and\\or digits    \n",
    "    # insert spaces between special characters to isolate them    \n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    document = special_char_pattern.sub(\" \\\\1 \", document)\n",
    "    document = remove_special_characters(document, remove_digits=True)  \n",
    "        \n",
    "    # remove extra whitespace\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    document = document.strip()\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_words = pre_process_text(dataset[:, 1])\n",
    "sv_words = pre_process_text(dataset[:, 2])\n",
    "t_stats = Counter(dataset[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_util(lprop, lload, n):\n",
    "    a = list(map(lambda x:(x - 1/7)**2, lprop))\n",
    "    b = lload[lprop.index(max(lprop))]\n",
    "    \n",
    "    return sum([aa * bb for aa, bb in zip(a, lload)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_word_label(labels, sentences):\n",
    "    en_stats = defaultdict(dict)\n",
    "\n",
    "    for label, line in zip(labels, sentences):\n",
    "        seen = set()\n",
    "        for w in line.split():\n",
    "            if w not in seen:\n",
    "                en_stats[w][label] = en_stats[w].get(label, 0) + 1\n",
    "                en_stats[w]['n'] = en_stats[w].get('n', 0) + 1\n",
    "                seen.add(w)\n",
    "    utils = []\n",
    "    for k in en_stats:\n",
    "        label_prop = []\n",
    "        label_load = []\n",
    "        for t in topics:\n",
    "            en_stats[k][t] = en_stats[k].get(t, 0)\n",
    "            label_prop.append(en_stats[k][t]/en_stats[k]['n'])\n",
    "            label_load.append(en_stats[k][t]/t_stats[t])\n",
    "        en_stats[k]['lprop'] = label_prop\n",
    "        en_stats[k]['lload'] = label_load\n",
    "        \n",
    "        utility = get_util(label_prop, label_load, en_stats[k]['n'])\n",
    "        utils.append(utility)\n",
    "        en_stats[k]['u'] = utility\n",
    "        \n",
    "    return en_stats, utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stats, en_u = compute_per_word_label(dataset[:,0], en_words)\n",
    "\n",
    "sv_stats,sv_u = compute_per_word_label(dataset[:,0], sv_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_util(en_stats, n = 20):\n",
    "    return sorted(en_stats.items(), key = lambda k : k[1]['u'], reverse = True)[:n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #    word           label         u     mplp  mpll   |   #    word           label         u     mplp  mpll \n",
      " 1    add        AddToPlaylist     0.588 0.996 0.809  |   1    lagg       AddToPlaylist     0.497 0.995 0.683\n",
      " 2    play         PlayMusic       0.539 0.924 0.883  |   2    boka       BookRestaurant    0.435 0.966 0.642\n",
      " 3  playlist     AddToPlaylist     0.398 0.931  0.64  |   3 spellista     AddToPlaylist     0.378 0.942 0.592\n",
      " 4    rate          RateBook       0.374 0.997 0.512  |   4   spela         PlayMusic       0.355 0.782 0.867\n",
      " 5  weather        GetWeather      0.322 0.999  0.44  |   5    till       AddToPlaylist     0.333 0.775 0.829\n",
      " 6   movie    SearchScreeningEvent 0.308 0.917 0.514  |   6    bord       BookRestaurant    0.262 0.994 0.361\n",
      " 7 restaurant    BookRestaurant    0.269 0.993 0.372  |   7 restaurang    BookRestaurant    0.259 0.993 0.358\n",
      " 8    book       BookRestaurant     0.24 0.764 0.622  |   8   filmer   SearchScreeningEvent 0.238 0.995 0.327\n",
      " 9     be          GetWeather      0.219 0.909 0.373  |   9   kommer        GetWeather      0.231 0.915 0.388\n",
      "10    will         GetWeather      0.213 0.924 0.347  |  10    det          GetWeather      0.216 0.716 0.653\n",
      "11   points         RateBook       0.209 0.998 0.286  |  11   poang          RateBook       0.209   1.0 0.284\n",
      "12  forecast       GetWeather      0.208   1.0 0.283  |  12  stjarnor        RateBook       0.208 0.986 0.293\n",
      "13    out           RateBook       0.206 0.915 0.345  |  13   vader         GetWeather      0.205 0.998  0.28\n",
      "14   stars          RateBook         0.2 0.976 0.288  |  14 betygsatt        RateBook       0.183   1.0 0.249\n",
      "15  playing   SearchScreeningEvent 0.192 0.978 0.276  |  15    min        AddToPlaylist     0.179 0.766 0.459\n",
      "16   table       BookRestaurant    0.191 0.992 0.265  |  16   musik         PlayMusic       0.151 0.912 0.255\n",
      "17     my        AddToPlaylist      0.19 0.741 0.527  |  17    film    SearchScreeningEvent 0.138 0.909 0.235\n",
      "18    give          RateBook       0.178 0.873 0.333  |  18   priser         RateBook       0.138 0.992 0.192\n",
      "19     it          GetWeather      0.177 0.896 0.311  |  19    bli          GetWeather      0.125 0.997 0.172\n",
      "20   movies   SearchScreeningEvent 0.172 0.992 0.239  |  20  biograf   SearchScreeningEvent 0.123 0.997 0.168\n"
     ]
    }
   ],
   "source": [
    "def get_present_strint(w, i=''):\n",
    "    return '{:2} {} {} {:5.3} {:5.3} {:5.3}'.format(i+1,  w[0].center(10), topics[w[1]['lprop'].index(max(w[1]['lprop']))].center(20), w[1]['u'], max(w[1]['lprop']),w[1]['lload'][w[1]['lprop'].index(max(w[1]['lprop']))])\n",
    "\n",
    "header = '{:2} {:10} {:20} {:5} {:5} {:5}'.format(' #', 'word'.center(10), 'label'.center(20), 'u', 'mplp', 'mpll')\n",
    "print(header, ' | ', header)\n",
    "for i,w,s in zip(range(30),get_top_util(en_stats),get_top_util(sv_stats)):\n",
    "    print(get_present_strint(w,i),' | ', get_present_strint(s,i))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_labels_stats = defaultdict(list)\n",
    "\n",
    "for k, v in en_stats.items():\n",
    "    if v['n'] < 30:\n",
    "        continue\n",
    "    for kk, vv in v.items():\n",
    "        if kk == 'n':\n",
    "            continue\n",
    "        en_labels_stats[kk].append((vv/v['n'],v['n'], k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_labels_stats['BookRestaurant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BookRestaurant': 1014,\n",
       " 'n': 2105,\n",
       " 'GetWeather': 274,\n",
       " 'SearchScreeningEvent': 764,\n",
       " 'RateBook': 19,\n",
       " 'SearchCreativeWork': 24,\n",
       " 'AddToPlaylist': 8,\n",
       " 'PlayMusic': 2}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stats['at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
