{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv, random, time\n",
    "\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open('data/snips_processed/snips.csv', 'r') as f:\n",
    "    reader = csv.reader(x.replace('\\0', '') for x in f)\n",
    "    for line in reader:\n",
    "        dataset.append(line)\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "testset = dataset[10000 :]\n",
    "\n",
    "trainset = dataset[:10000]\n",
    "\n",
    "train_sent_en = trainset[:,1]\n",
    "#train_sent_sv = trainset[:,2]\n",
    "train_lab = trainset[:,0]\n",
    "\n",
    "test_sent_en = testset[:,1]\n",
    "#test_sent_sv = testset[:,2]\n",
    "test_lab = testset[:,0]\n",
    "\n",
    "labels = list(set(test_lab))\n",
    "lab2id = {}\n",
    "id2lab = {}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    lab2id[labels[i]] = i\n",
    "    id2lab[i] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3784, array(['RateBook',\n",
       "        'I give The Lady Decides a rating value of 4 and a best rating of 6',\n",
       "        'Jag ger Damen Bestämmer sig för ett betyg värde av 4 och en bäst betyg av 6'],\n",
       "       dtype='<U187'))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset), trainset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "@np.vectorize\n",
    "def pre_process_documents(document):\n",
    "    \n",
    "    # lower case\n",
    "    document = document.lower()\n",
    "    \n",
    "    # remove extra newlines (often might be present in really noisy text)\n",
    "    document = document.translate(document.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    \n",
    "    # remove accented characters\n",
    "    document = remove_accented_chars(document)\n",
    "    \n",
    "    # expand contractions    \n",
    "    document = expand_contractions(document)\n",
    "               \n",
    "    # remove special characters and\\or digits    \n",
    "    # insert spaces between special characters to isolate them    \n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    document = special_char_pattern.sub(\" \\\\1 \", document)\n",
    "    document = remove_special_characters(document, remove_digits=True)  \n",
    "        \n",
    "    # remove extra whitespace\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    document = document.strip()\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Saving graph from tutorial  https://rentry.co/nxpua\n",
    "\n",
    "from tensorflow.saved_model import simple_save\n",
    "\n",
    "export_dir = \"models/universal_encoder/00000001\"\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\") \n",
    "    print('module downloaded')\n",
    "    input_params = module.get_input_info_dict()\n",
    "\n",
    "    text_input = tf.placeholder(name='text', dtype=input_params['text'].dtype, \n",
    "        shape=input_params['text'].get_shape())\n",
    "    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "    embeddings = module(text_input)\n",
    "\n",
    "    simple_save(sess,\n",
    "        export_dir,\n",
    "        inputs={'text': text_input},\n",
    "        outputs={'embeddings': embeddings},\n",
    "        legacy_init_op=tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_vecs(sents):\n",
    "    \n",
    "    r = requests.post(\n",
    "            'http://localhost:8501/v1/models/universal_encoder:predict', \n",
    "            json={'inputs': {'text': sents}})\n",
    "\n",
    "    responce = r.json() \n",
    "    return responce['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labs(labs):\n",
    "    out = []\n",
    "    for lab in labs:\n",
    "        out.append(lab2id[lab])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, in_size = 512, out_size = 7):\n",
    "        super(Baseline, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(in_size, 7)\n",
    "        self.out = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.W(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "def train(model, criterion, optimizer, labels, vectors):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    vectors = torch.tensor(vectors).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    model_out = model.forward(vectors)\n",
    "    loss += criterion(model_out[:,0], labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()/len(labels)\n",
    "\n",
    "def eval(model, labels, vectors):\n",
    "    with torch.no_grad():\n",
    "        vectors = torch.tensor(vectors).float()\n",
    "        labels = torch.tensor(labels)\n",
    "    \n",
    "        model_out = model.forward(vectors)\n",
    "        right = 0\n",
    "        \n",
    "        for i  in range(len(model_out)):\n",
    "            k, v = model_out[i].topk(1)\n",
    "            predicted, true = v.item(), labels[i].item()\n",
    "            if predicted == true:\n",
    "                right +=1\n",
    "\n",
    "                \n",
    "        loss = criterion(model_out[:,0], labels)\n",
    "        return loss.item(), right/len(model_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = prepare_labs(train_lab)\n",
    "test_labs = prepare_labs(test_lab)\n",
    "\n",
    "train_sent_en = list(pre_process_documents(train_sent_en))\n",
    "\n",
    "train_vecs = []\n",
    "for i in range(0,len(train_sent_en),100):\n",
    "    train_vecs.extend(get_vecs(train_sent_en[i:i+100]))\n",
    "\n",
    "    \n",
    "test_sent_en = list(pre_process_documents(test_sent_en))\n",
    "\n",
    "test_vecs = []\n",
    "for i in range(0,len(test_sent_en),100):\n",
    "    test_vecs.extend(get_vecs(test_sent_en[i:i+100]))\n",
    "    \n",
    "test_vecs = list(map(lambda x: np.array([x]) , test_vecs))\n",
    "train_vecs = list(map(lambda x: np.array([x]) , train_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,     0 sec. train loss: 0.0001950, eval loss: 1.9424, acc = 0.159\n",
      "#100,    56 sec. train loss: 0.0001267, eval loss: 1.2629, acc = 0.912\n",
      "#200,   126 sec. train loss: 0.0000862, eval loss: 0.8616, acc = 0.921\n",
      "#300,   194 sec. train loss: 0.0000636, eval loss: 0.6392, acc = 0.925\n",
      "#400,   264 sec. train loss: 0.0000504, eval loss: 0.5087, acc = 0.934\n",
      "#500,   330 sec. train loss: 0.0000419, eval loss: 0.4256, acc = 0.938\n",
      "#600,   396 sec. train loss: 0.0000361, eval loss: 0.3687, acc = 0.942\n",
      "#700,   457 sec. train loss: 0.0000319, eval loss: 0.3276, acc = 0.946\n",
      "#800,   540 sec. train loss: 0.0000288, eval loss: 0.2965, acc = 0.950\n",
      "#900,   606 sec. train loss: 0.0000263, eval loss: 0.2722, acc = 0.952\n",
      "#1000,   669 sec. train loss: 0.0000243, eval loss: 0.2526, acc = 0.953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-136a2c6752d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-068a375d84fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, labels, vectors)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Baseline()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(4001):\n",
    "    loss = train(net, criterion, optimizer, train_labs, train_vecs)\n",
    "    if not i% 100:\n",
    "        eval_loss, acc = eval(net, test_labs, test_vecs)\n",
    "        print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.3f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['give this album of points', 'book a table at atlantic grill in lofgreen', 'give the current album out of points', 'i give the lady decides a rating value of and a best rating of', 'add la voce to my dubstep dangles dirty playlist', 'play any chanson', 'rate the previous essay four of points', 'give the current novel a one out of rating', 'this current book should get four stars or a rating of']\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "vecs = []\n",
    "\n",
    "a = list(pre_process_documents(dataset[:,1]))\n",
    "print(a[1:10])\n",
    "for i in range(0,len(a),100):\n",
    "    vecs.extend(get_vecs(a[i:i+100]))\n",
    "    print(i//100)\n",
    "    \n",
    "vecs = list(map(lambda x: np.array([x]) , vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nptv2s = np.array(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/snips_processed/USE-en',np.array(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = prepare_labs(dataset[:, 0])\n",
    "np.save('data/snips_processed/labs',np.array(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarity/Code/virtualenvs/main/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Baseline. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, 'models/USE-linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
