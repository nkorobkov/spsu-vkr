{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv, random, time\n",
    "\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = []\n",
    "with open('data/snips_processed/snips.csv', 'r') as f:\n",
    "    reader = csv.reader(x.replace('\\0', '') for x in f)\n",
    "    for line in reader:\n",
    "        trainset.append(line)\n",
    "trainset = np.array(trainset)\n",
    "\n",
    "testset = trainset[10000 :]\n",
    "\n",
    "trainset = trainset[:10000]\n",
    "\n",
    "train_sent_en = trainset[:,1]\n",
    "#train_sent_sv = trainset[:,2]\n",
    "train_lab = trainset[:,0]\n",
    "\n",
    "test_sent_en = testset[:,1]\n",
    "#test_sent_sv = testset[:,2]\n",
    "test_lab = testset[:,0]\n",
    "\n",
    "labels = list(set(test_lab))\n",
    "lab2id = {}\n",
    "id2lab = {}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    lab2id[labels[i]] = i\n",
    "    id2lab[i] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3784, array(['RateBook',\n",
       "        'I give The Lady Decides a rating value of 4 and a best rating of 6',\n",
       "        'Jag ger Damen Bestämmer sig för ett betyg värde av 4 och en bäst betyg av 6'],\n",
       "       dtype='<U187'))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset), trainset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "@np.vectorize\n",
    "def pre_process_documents(document):\n",
    "    \n",
    "    # lower case\n",
    "    document = document.lower()\n",
    "    \n",
    "    # remove extra newlines (often might be present in really noisy text)\n",
    "    document = document.translate(document.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    \n",
    "    # remove accented characters\n",
    "    document = remove_accented_chars(document)\n",
    "    \n",
    "    # expand contractions    \n",
    "    document = expand_contractions(document)\n",
    "               \n",
    "    # remove special characters and\\or digits    \n",
    "    # insert spaces between special characters to isolate them    \n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    document = special_char_pattern.sub(\" \\\\1 \", document)\n",
    "    document = remove_special_characters(document, remove_digits=True)  \n",
    "        \n",
    "    # remove extra whitespace\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    document = document.strip()\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Saving graph from tutorial  https://rentry.co/nxpua\n",
    "\n",
    "from tensorflow.saved_model import simple_save\n",
    "\n",
    "export_dir = \"models/universal_encoder/00000001\"\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    module = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\") \n",
    "    print('module downloaded')\n",
    "    input_params = module.get_input_info_dict()\n",
    "\n",
    "    text_input = tf.placeholder(name='text', dtype=input_params['text'].dtype, \n",
    "        shape=input_params['text'].get_shape())\n",
    "    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "    embeddings = module(text_input)\n",
    "\n",
    "    simple_save(sess,\n",
    "        export_dir,\n",
    "        inputs={'text': text_input},\n",
    "        outputs={'embeddings': embeddings},\n",
    "        legacy_init_op=tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_vecs(sents):\n",
    "    \n",
    "    r = requests.post(\n",
    "            'http://localhost:8501/v1/models/universal_encoder:predict', \n",
    "            json={'inputs': {'text': sents}})\n",
    "\n",
    "    responce = r.json() \n",
    "    return responce['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labs(labs):\n",
    "    out = []\n",
    "    for lab in labs:\n",
    "        out.append(lab2id[lab])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, in_size = 512, out_size = 7):\n",
    "        super(Baseline, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(in_size, 7)\n",
    "        self.out = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.W(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "def train(model, criterion, optimizer, labels, vectors):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    vectors = torch.tensor(vectors).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    model_out = model.forward(vectors)\n",
    "    loss += criterion(model_out[:,0], labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()/len(labels)\n",
    "\n",
    "def eval(model, labels, vectors):\n",
    "    with torch.no_grad():\n",
    "        vectors = torch.tensor(vectors).float()\n",
    "        labels = torch.tensor(labels)\n",
    "    \n",
    "        model_out = model.forward(vectors)\n",
    "        right = 0\n",
    "        \n",
    "        for i  in range(len(model_out)):\n",
    "            k, v = model_out[i].topk(1)\n",
    "            predicted, true = v.item(), labels[i].item()\n",
    "            if predicted == true:\n",
    "                right +=1\n",
    "\n",
    "                \n",
    "        loss = criterion(model_out[:,0], labels)\n",
    "        return loss.item(), right/len(model_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = prepare_labs(train_lab)\n",
    "test_labs = prepare_labs(test_lab)\n",
    "\n",
    "train_sent_en = list(pre_process_documents(train_sent_en))\n",
    "\n",
    "train_vecs = []\n",
    "for i in range(0,len(train_sent_en),100):\n",
    "    train_vecs.extend(get_vecs(train_sent_en[i:i+100]))\n",
    "\n",
    "    \n",
    "test_sent_en = list(pre_process_documents(test_sent_en))\n",
    "\n",
    "test_vecs = []\n",
    "for i in range(0,len(test_sent_en),100):\n",
    "    test_vecs.extend(get_vecs(test_sent_en[i:i+100]))\n",
    "    \n",
    "test_vecs = list(map(lambda x: np.array([x]) , test_vecs))\n",
    "train_vecs = list(map(lambda x: np.array([x]) , train_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,     0 sec. train loss: 0.0001944, eval loss: 1.9351, acc = 0.250\n",
      "#100,    65 sec. train loss: 0.0001263, eval loss: 1.2580, acc = 0.914\n",
      "#200,   136 sec. train loss: 0.0000859, eval loss: 0.8588, acc = 0.923\n",
      "#300,   200 sec. train loss: 0.0000635, eval loss: 0.6375, acc = 0.928\n",
      "#400,   265 sec. train loss: 0.0000503, eval loss: 0.5077, acc = 0.934\n",
      "#500,   332 sec. train loss: 0.0000419, eval loss: 0.4250, acc = 0.939\n",
      "#600,   393 sec. train loss: 0.0000361, eval loss: 0.3683, acc = 0.942\n",
      "#700,   468 sec. train loss: 0.0000319, eval loss: 0.3274, acc = 0.946\n",
      "#800,   543 sec. train loss: 0.0000288, eval loss: 0.2964, acc = 0.950\n",
      "#900,   609 sec. train loss: 0.0000263, eval loss: 0.2721, acc = 0.952\n",
      "#1000,   666 sec. train loss: 0.0000243, eval loss: 0.2526, acc = 0.953\n",
      "#1100,   722 sec. train loss: 0.0000226, eval loss: 0.2366, acc = 0.954\n",
      "#1200,   778 sec. train loss: 0.0000213, eval loss: 0.2232, acc = 0.956\n",
      "#1300,   834 sec. train loss: 0.0000201, eval loss: 0.2118, acc = 0.957\n",
      "#1400,   893 sec. train loss: 0.0000191, eval loss: 0.2020, acc = 0.958\n",
      "#1500,   956 sec. train loss: 0.0000182, eval loss: 0.1934, acc = 0.959\n",
      "#1600,  1018 sec. train loss: 0.0000174, eval loss: 0.1859, acc = 0.959\n",
      "#1700,  1080 sec. train loss: 0.0000167, eval loss: 0.1793, acc = 0.960\n",
      "#1800,  1139 sec. train loss: 0.0000161, eval loss: 0.1733, acc = 0.960\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-136a2c6752d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-068a375d84fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, labels, vectors)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Baseline()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(4001):\n",
    "    loss = train(net, criterion, optimizer, train_labs, train_vecs)\n",
    "    if not i% 100:\n",
    "        eval_loss, acc = eval(net, test_labs, test_vecs)\n",
    "        print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.3f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nptv2s = np.array(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/snips_processed/USE-en-train',np.array(train_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/snips_processed/train-labs',np.array(train_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'models/USE-linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
