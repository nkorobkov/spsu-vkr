{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import contractions\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainset = []\n",
    "with open('data/snips_processed/snips.csv', 'r') as f:\n",
    "    reader = csv.reader(x.replace('\\0', '') for x in f)\n",
    "    for line in reader:\n",
    "        trainset.append(line)\n",
    "trainset = np.array(trainset)\n",
    "\n",
    "testset = trainset[10000 :]\n",
    "\n",
    "trainset = trainset[:10000]\n",
    "\n",
    "train_sent_en = trainset[:,1]\n",
    "#train_sent_sv = trainset[:,2]\n",
    "train_lab = trainset[:,0]\n",
    "\n",
    "testset = []\n",
    "with open('data/snips_processed/snips.csv', 'r') as f:\n",
    "    reader = csv.reader(x.replace('\\0', '') for x in f)\n",
    "    for line in reader:\n",
    "        testset.append(line)\n",
    "testset = np.array(testset)\n",
    "\n",
    "test_sent_en = testset[:,1]\n",
    "#test_sent_sv = testset[:,2]\n",
    "test_lab = testset[:,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels = list(set(test_lab))\n",
    "lab2id = {}\n",
    "id2lab = {}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    lab2id[labels[i]] = i\n",
    "    id2lab[i] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'SearchScreeningEvent',\n",
       " 1: 'RateBook',\n",
       " 2: 'AddToPlaylist',\n",
       " 3: 'PlayMusic',\n",
       " 4: 'GetWeather',\n",
       " 5: 'SearchCreativeWork',\n",
       " 6: 'BookRestaurant'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 13:25:04,017 INFO: char embedding size: 4939\n",
      "2019-04-17 13:25:04,831 INFO: word embedding size: 167642\n",
      "2019-04-17 13:25:12,257 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(167642, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(4939, 50, padding_idx=4936)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "\n",
    "en_model = Embedder('models/144')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 13:14:28,443 INFO: 1 batches, avg len: 6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [['what', 'is','my','name'],['my','name','is','Jan']]\n",
    "# the list of lists which store the sentences \n",
    "# after segment if necessary.\n",
    "a = en_model.sents2elmo(sents)\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "@np.vectorize\n",
    "def pre_process_text(document):\n",
    "    \n",
    "    # lower case\n",
    "    document = document.lower()\n",
    "    \n",
    "    # remove extra newlines (often might be present in really noisy text)\n",
    "    document = document.translate(document.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    \n",
    "    # remove accented characters\n",
    "    document = remove_accented_chars(document)\n",
    "    \n",
    "    # expand contractions    \n",
    "    document = expand_contractions(document)\n",
    "               \n",
    "    # remove special characters and\\or digits    \n",
    "    # insert spaces between special characters to isolate them    \n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    document = special_char_pattern.sub(\" \\\\1 \", document)\n",
    "    document = remove_special_characters(document, remove_digits=True)  \n",
    "        \n",
    "    # remove extra whitespace\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    document = document.strip()\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i want to rate the turbulent term of tyke tiler a',\n",
       "       'when is the great question playing at the closest movie house',\n",
       "       'will mondamin be hot on july', ...,\n",
       "       'give me the movie times for fox theatres',\n",
       "       'can i get the movie times for fox theatres',\n",
       "       'what movies are scheduled in the neighbourhood'], dtype='<U127')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process_text(test_sent_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vec(sentence, model):\n",
    "    result = np.zeros((1, 1024))\n",
    "    sentence = pre_process_te(sentence)\n",
    "    sentence = list(map(lambda x: x.split(), sentence\n",
    "    \n",
    "    \n",
    "    for word in sentence:\n",
    "        result += model.get_word_vector(word.lower())\n",
    "    return result/len(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labs(labs):\n",
    "    out = []\n",
    "    for lab in labs:\n",
    "        out.append(lab2id[lab])\n",
    "    return out\n",
    "\n",
    "def prepare_sentence_vecs(sents, lang = 'en'):\n",
    "    \n",
    "    if lang == 'en':\n",
    "        model = en_model\n",
    "        slab = 1\n",
    "    elif lang == 'sv':\n",
    "        model = sv_model\n",
    "        slab = 2\n",
    "    else:\n",
    "        raise RuntimeError('lang is not supported')\n",
    "    vectors = []\n",
    "    \n",
    "    sents = pre_process_text(sents)\n",
    "    sents = list(map(lambda x: x.split(), sents))\n",
    "    vecs = model.sents2elmo(sents)\n",
    "    vecs = list(map(lambda x:[x.mean(axis=0)], vecs))\n",
    "        \n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, in_size = 1024, out_size = 7):\n",
    "        super(Baseline, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(in_size, 7)\n",
    "        self.out = nn.LogSoftmax(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.W(x)\n",
    "        return self.out(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, labels, vectors):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    vectors = torch.tensor(vectors).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    model_out = model.forward(vectors)\n",
    "    loss += criterion(model_out[:,0], labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, labels, vectors):\n",
    "    with torch.no_grad():\n",
    "        vectors = torch.tensor(vectors).float()\n",
    "        labels = torch.tensor(labels)\n",
    "    \n",
    "        model_out = model.forward(vectors)\n",
    "        right = 0\n",
    "        \n",
    "        for i  in range(len(model_out)):\n",
    "            k, v = model_out[i].topk(1)\n",
    "            predicted, true = v.item(), labels[i].item()\n",
    "            if predicted == true:\n",
    "                right +=1\n",
    "\n",
    "                \n",
    "        loss = criterion(model_out[:,0], labels)\n",
    "        return loss.item(), right/len(model_out)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vecs, labss = prepare_sentence_vecs(train_sent_en), prepare_labs(train_lab)\n",
    "#vecst, labst = prepare_sentence_vecs(test_sent_en), prepare_labs(test_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,     2 sec. train loss: 0.0002024, eval loss: 1.9434, acc = 0.156\n",
      "#100,   116 sec. train loss: 0.0000291, eval loss: 2.0364, acc = 0.601\n",
      "#200,   222 sec. train loss: 0.0000158, eval loss: 2.0020, acc = 0.691\n",
      "#300,   324 sec. train loss: 0.0000112, eval loss: 2.0452, acc = 0.699\n",
      "#400,   425 sec. train loss: 0.0000088, eval loss: 2.0888, acc = 0.702\n",
      "#500,   557 sec. train loss: 0.0000074, eval loss: 2.1245, acc = 0.705\n",
      "#600,   672 sec. train loss: 0.0000064, eval loss: 2.1521, acc = 0.707\n",
      "#700,   778 sec. train loss: 0.0000056, eval loss: 2.1725, acc = 0.708\n",
      "#800,   883 sec. train loss: 0.0000050, eval loss: 2.1866, acc = 0.709\n",
      "#900,   986 sec. train loss: 0.0000046, eval loss: 2.1952, acc = 0.710\n",
      "#1000,  1090 sec. train loss: 0.0000042, eval loss: 2.1992, acc = 0.710\n",
      "#1100,  1193 sec. train loss: 0.0000038, eval loss: 2.1992, acc = 0.711\n",
      "#1200,  1297 sec. train loss: 0.0000035, eval loss: 2.1957, acc = 0.712\n",
      "#1300,  3699 sec. train loss: 0.0000033, eval loss: 2.1894, acc = 0.712\n",
      "#1400,  3813 sec. train loss: 0.0000031, eval loss: 2.1809, acc = 0.713\n",
      "#1500,  3916 sec. train loss: 0.0000029, eval loss: 2.1710, acc = 0.713\n",
      "#1600,  4004 sec. train loss: 0.0000027, eval loss: 2.1606, acc = 0.713\n",
      "#1700,  4087 sec. train loss: 0.0000025, eval loss: 2.1509, acc = 0.714\n",
      "#1800,  4169 sec. train loss: 0.0000024, eval loss: 2.1435, acc = 0.714\n",
      "#1900,  4251 sec. train loss: 0.0000022, eval loss: 2.1399, acc = 0.714\n",
      "#2000,  4334 sec. train loss: 0.0000021, eval loss: 2.1412, acc = 0.714\n",
      "#2100,  4416 sec. train loss: 0.0000020, eval loss: 2.1472, acc = 0.714\n",
      "#2200,  4498 sec. train loss: 0.0000019, eval loss: 2.1572, acc = 0.715\n",
      "#2300,  6613 sec. train loss: 0.0000018, eval loss: 2.1702, acc = 0.715\n",
      "#2400, 16455 sec. train loss: 0.0000017, eval loss: 2.1851, acc = 0.715\n",
      "#2500, 28366 sec. train loss: 0.0000016, eval loss: 2.2013, acc = 0.715\n",
      "#2600, 29263 sec. train loss: 0.0000015, eval loss: 2.2181, acc = 0.715\n",
      "#2700, 29350 sec. train loss: 0.0000014, eval loss: 2.2354, acc = 0.715\n",
      "#2800, 29435 sec. train loss: 0.0000013, eval loss: 2.2529, acc = 0.715\n",
      "#2900, 29517 sec. train loss: 0.0000013, eval loss: 2.2704, acc = 0.716\n",
      "#3000, 29607 sec. train loss: 0.0000012, eval loss: 2.2879, acc = 0.716\n",
      "#3100, 29692 sec. train loss: 0.0000012, eval loss: 2.3053, acc = 0.716\n",
      "#3200, 29774 sec. train loss: 0.0000011, eval loss: 2.3226, acc = 0.716\n",
      "#3300, 29855 sec. train loss: 0.0000010, eval loss: 2.3397, acc = 0.716\n",
      "#3400, 29935 sec. train loss: 0.0000010, eval loss: 2.3566, acc = 0.716\n",
      "#3500, 30017 sec. train loss: 0.0000009, eval loss: 2.3732, acc = 0.716\n",
      "#3600, 30106 sec. train loss: 0.0000009, eval loss: 2.3896, acc = 0.716\n",
      "#3700, 30194 sec. train loss: 0.0000008, eval loss: 2.4058, acc = 0.716\n",
      "#3800, 30278 sec. train loss: 0.0000008, eval loss: 2.4217, acc = 0.716\n",
      "#3900, 30362 sec. train loss: 0.0000008, eval loss: 2.4373, acc = 0.716\n",
      "#4000, 30445 sec. train loss: 0.0000007, eval loss: 2.4528, acc = 0.716\n"
     ]
    }
   ],
   "source": [
    "net = Baseline()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "t = time.time()\n",
    "for i in range(4001):\n",
    "    loss = train(net, criterion, optimizer, labs, vecs)\n",
    "    if not i% 100:\n",
    "        eval_loss, acc = eval(net, labst, vecst)\n",
    "        print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.3f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#   0, train loss: 0.000214, eval loss: 2.296857, acc = 0.148974\n",
      "# 100, train loss: 0.000048, eval loss: 0.526288, acc = 0.851026\n",
      "# 200, train loss: 0.000037, eval loss: 0.406894, acc = 0.851026\n",
      "# 300, train loss: 0.000033, eval loss: 0.360803, acc = 0.853185\n",
      "# 400, train loss: 0.000030, eval loss: 0.331020, acc = 0.862540\n",
      "# 500, train loss: 0.000028, eval loss: 0.309052, acc = 0.870817\n",
      "# 600, train loss: 0.000027, eval loss: 0.292021, acc = 0.879813\n",
      "# 700, train loss: 0.000026, eval loss: 0.278468, acc = 0.890248\n",
      "# 800, train loss: 0.000025, eval loss: 0.267494, acc = 0.898884\n",
      "# 900, train loss: 0.000024, eval loss: 0.258484, acc = 0.902123\n",
      "#1000, train loss: 0.000023, eval loss: 0.251004, acc = 0.903922\n",
      "#1100, train loss: 0.000023, eval loss: 0.244733, acc = 0.908960\n",
      "#1200, train loss: 0.000022, eval loss: 0.239429, acc = 0.911479\n",
      "#1300, train loss: 0.000022, eval loss: 0.234910, acc = 0.912199\n",
      "#1400, train loss: 0.000021, eval loss: 0.231031, acc = 0.914358\n",
      "#1500, train loss: 0.000021, eval loss: 0.227682, acc = 0.917596\n",
      "#1600, train loss: 0.000021, eval loss: 0.224775, acc = 0.919036\n",
      "#1700, train loss: 0.000021, eval loss: 0.222237, acc = 0.920115\n",
      "#1800, train loss: 0.000020, eval loss: 0.220012, acc = 0.921555\n",
      "#1900, train loss: 0.000020, eval loss: 0.218054, acc = 0.922274\n",
      "#2000, train loss: 0.000020, eval loss: 0.216324, acc = 0.922994\n",
      "#2100, train loss: 0.000020, eval loss: 0.214789, acc = 0.924433\n",
      "#2200, train loss: 0.000020, eval loss: 0.213423, acc = 0.925873\n",
      "#2300, train loss: 0.000020, eval loss: 0.212205, acc = 0.926232\n",
      "#2400, train loss: 0.000020, eval loss: 0.211115, acc = 0.926592\n",
      "#2500, train loss: 0.000020, eval loss: 0.210136, acc = 0.927312\n",
      "#2600, train loss: 0.000020, eval loss: 0.209255, acc = 0.927312\n",
      "#2700, train loss: 0.000019, eval loss: 0.208460, acc = 0.927672\n",
      "#2800, train loss: 0.000019, eval loss: 0.207741, acc = 0.928032\n",
      "#2900, train loss: 0.000019, eval loss: 0.207089, acc = 0.927672\n",
      "#3000, train loss: 0.000019, eval loss: 0.206495, acc = 0.927312\n",
      "#3100, train loss: 0.000019, eval loss: 0.205953, acc = 0.928392\n",
      "#3200, train loss: 0.000019, eval loss: 0.205457, acc = 0.928392\n",
      "#3300, train loss: 0.000019, eval loss: 0.205001, acc = 0.928392\n",
      "#3400, train loss: 0.000019, eval loss: 0.204582, acc = 0.929111\n",
      "#3500, train loss: 0.000019, eval loss: 0.204194, acc = 0.929471\n",
      "#3600, train loss: 0.000019, eval loss: 0.203834, acc = 0.929471\n",
      "#3700, train loss: 0.000019, eval loss: 0.203498, acc = 0.929471\n",
      "#3800, train loss: 0.000019, eval loss: 0.203185, acc = 0.929831\n",
      "#3900, train loss: 0.000019, eval loss: 0.202891, acc = 0.930191\n",
      "#4000, train loss: 0.000019, eval loss: 0.202613, acc = 0.930191\n"
     ]
    }
   ],
   "source": [
    "net = Baseline()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "criterion = torch.nn.NLLLoss()\n",
    "labs, vecs = prepare_pairs(trainset, lang = 'en')\n",
    "labst, vecst = prepare_pairs(testset, lang = 'en')\n",
    "\n",
    "\n",
    "for i in range(4001):\n",
    "    loss = train(net, criterion, optimizer, labs, vecs)\n",
    "    if not i% 100:\n",
    "        eval_loss, acc = eval(net, labst, vecst)\n",
    "        print('#{:4d}, train loss: {:3f}, eval loss: {:3f}, acc = {:3f}'.format(i, loss, eval_loss, acc))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_visual(model, labels, vectors):\n",
    "    with torch.no_grad():\n",
    "        vectors = torch.tensor(vectors).float()\n",
    "        labels = torch.tensor(labels)\n",
    "    \n",
    "        model_out = model.forward(vectors)\n",
    "        right = 0\n",
    "        wrong = 0\n",
    "        for i  in range(len(model_out)):\n",
    "            k, v = model_out[i].topk(1)\n",
    "            predicted, true = v.item(), labels[i].item()\n",
    "            if predicted == true:\n",
    "                right +=1\n",
    "            else:\n",
    "                print(id2lab[predicted], id2lab[true])\n",
    "                wrong +=1\n",
    "                \n",
    "        print('{} out of {} = {}'.format(right, right+wrong, right/(right+wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComparePlaces GetPlaceDetails\n",
      "SearchPlace RequestRide\n",
      "BookRestaurant GetWeather\n",
      "GetPlaceDetails GetWeather\n",
      "RequestRide GetTrafficInformation\n",
      "SearchPlace GetPlaceDetails\n",
      "GetTrafficInformation GetDirections\n",
      "GetPlaceDetails GetWeather\n",
      "GetDirections GetPlaceDetails\n",
      "GetWeather GetPlaceDetails\n",
      "GetDirections SearchPlace\n",
      "SearchPlace ShareETA\n",
      "SearchPlace GetPlaceDetails\n",
      "GetPlaceDetails GetTrafficInformation\n",
      "GetTrafficInformation GetWeather\n",
      "GetWeather ShareCurrentLocation\n",
      "GetPlaceDetails ComparePlaces\n",
      "SearchPlace BookRestaurant\n",
      "GetPlaceDetails GetTrafficInformation\n",
      "SearchPlace RequestRide\n",
      "ComparePlaces GetPlaceDetails\n",
      "GetWeather GetPlaceDetails\n",
      "GetDirections GetPlaceDetails\n",
      "GetWeather GetPlaceDetails\n",
      "GetPlaceDetails GetWeather\n",
      "RequestRide GetWeather\n",
      "BookRestaurant GetWeather\n",
      "BookRestaurant GetTrafficInformation\n",
      "50 out of 78 = 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "eval_visual(net, labst, vecst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['RateBook', 'rate the current textbook zero out of 6 points'],\n",
       "       ['BookRestaurant',\n",
       "        'restaurant in Elberta for alma, deana and olga at 18:49:20 that serves tsipouro'],\n",
       "       ['SearchScreeningEvent',\n",
       "        'What movies are currently at Star Theatres?'],\n",
       "       ...,\n",
       "       ['PlayMusic', 'Please play Different Slanguages by Fred Labour.'],\n",
       "       ['PlayMusic', 'play some King Tubby from the eighties'],\n",
       "       ['AddToPlaylist',\n",
       "        'add M-CABI to the playlist named Pre-Party R&B Jams']],\n",
       "      dtype='<U186')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 7])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(torch.tensor(vecs))[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(np.squeeze(np.array(vecs), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
