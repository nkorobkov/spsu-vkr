{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# use this library https://github.com/facebookresearch/fastText/tree/master/python\n",
    "import fastText\n",
    "\n",
    "import contractions\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset, lab2id, id2lab =import_data('data/snips_processed/snips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_model = fastText.load_model('data/cc.sv.300.bin')\n",
    "en_model = fastText.load_model('data/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vec(sentence, model):\n",
    "    result = np.zeros((1, 300))\n",
    "    for word in sentence.split():\n",
    "        result += model.get_word_vector(word)\n",
    "    return result/len(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence_vecs(data, lang = 'en', preprocess=False):\n",
    "    \n",
    "    if lang == 'en':\n",
    "        model = en_model\n",
    "        slab = 1\n",
    "    elif lang == 'sv':\n",
    "        model = sv_model\n",
    "        slab = 2\n",
    "    else:\n",
    "        raise RuntimeError('lang is not supported')\n",
    "    vectors = []\n",
    "    \n",
    "    sents = pre_process_text(data[:, slab])  if preprocess else data[:, slab]\n",
    "    vecs = list(map(lambda x:sentence_vec(x, model), sents))\n",
    "        \n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BookRestaurant': 0,\n",
       " 'GetWeather': 1,\n",
       " 'SearchScreeningEvent': 2,\n",
       " 'RateBook': 3,\n",
       " 'SearchCreativeWork': 4,\n",
       " 'AddToPlaylist': 5,\n",
       " 'PlayMusic': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en-done\n",
      "sv-done\n"
     ]
    }
   ],
   "source": [
    "vecs_en = prepare_sentence_vecs(dataset, lang='en', preprocess=True)\n",
    "print('en-done')\n",
    "vecs_sv = prepare_sentence_vecs(dataset, lang='sv', preprocess=True)\n",
    "print('sv-done')\n",
    "labs = prepare_labs(dataset[:,0], lab2id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train_model(train_vecs, train_labs, test_vecs, test_labs, verbose = False, runs = 4001):\n",
    "    net = Baseline(in_size=300)\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    \n",
    "    \n",
    "    tvecs = torch.tensor(train_vecs).float()\n",
    "    tvecst = torch.tensor(test_vecs).float()\n",
    "    tlabs = torch.tensor(train_labs)\n",
    "    tlabst = torch.tensor(test_labs)\n",
    "        \n",
    "    t = time.time()\n",
    "    for i in range(6001):\n",
    "        loss = train(net, criterion, optimizer, tlabs, tvecs)\n",
    "        if verbose and not i% 100:\n",
    "            eval_loss, acc = evaluate(net, tlabst, tvecst, criterion)\n",
    "            print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.3f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n",
    "    \n",
    "    eval_loss, acc = evaluate(net, tlabst, tvecst, criterion)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(vecs, labs, folds = 5):\n",
    "    \n",
    "    delims = np.arange(0, len(vecs), len(vecs)//folds)\n",
    "    results = []\n",
    "    t = time.time()\n",
    "    for i in range(folds):\n",
    "        results.append(\n",
    "            full_train_model(vecs[:delims[i]] + vecs[delims[i+1]:],\n",
    "                             labs[:delims[i]] + labs[delims[i+1]:],\n",
    "                             vecs[delims[i] : delims[i+1]],\n",
    "                             labs[delims[i] : delims[i+1]],\n",
    "                                  False, runs = 6001))\n",
    "        print('#{:3d}, {:5d} sec. acc = {:.3f}'.format(i, int(time.time() - t), results[-1]))\n",
    "\n",
    "    return(sum(results)/len(results))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    68 sec. acc = 0.914\n",
      "#  1,   135 sec. acc = 0.930\n",
      "#  2,   202 sec. acc = 0.919\n",
      "#  3,   267 sec. acc = 0.922\n",
      "#  4,   347 sec. acc = 0.913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9195210449927431"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_en, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,   289 sec. acc = 0.882\n",
      "#  1,  1332 sec. acc = 0.889\n",
      "#  2,  1571 sec. acc = 0.888\n",
      "#  3,  1660 sec. acc = 0.878\n",
      "#  4,  1735 sec. acc = 0.881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8835994194484762"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_sv, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs_sv[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(np.squeeze(np.array(vecs_en), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/snips_processed/FastText-en',np.array(vecs_en))\n",
    "np.save('data/snips_processed/FastText-sv',np.array(vecs_sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
