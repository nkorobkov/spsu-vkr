# Метод межязыковой адаптации диалоговых систем
*Коробков Никита*

### Введение

В последние годы все больше внимания уделяется решению различных задач с применением машинного обучения и нейронных сетей. Одним из наиболее интересных направлений в области применения современных нейросетевых методов являются диалоговые системы.  
Диалоговая система это набор программ и алгоритмов позволяющих человеку вести диалог с программой в манере свойственной человеческой. Иногда диалоговые системы называют разговорным искуственным интелектом или "чат-ботом". 
Задача построения подобных программ является актуальной для промышенной области потому, что решение задач пользователей путем диалога с агентом поддержки всегда было и будет оставаться наиболее простым и эффективным методом. Так как вербальное общение наиболее естественный для человека способ коммуникации. Построение хорошей и надежной диалоговой системы заменяющей работников колл центра позволило бы существенно сократить затраты рессурсов.  
Диалоговые системы можно разделить на системы общего назначения и задачеориентированные. Чем более узкую задачу призвана решать система, тем проще она может быть устроена. В самом тривиальном случае cистема может просто возвращать заранее известный ответ. Например текущее время.  
Мы хотели бы построить систему решающую более общую задачу. Для этого в нужно сначала выяснить детально чего именно хочет пользователь (задать вопрос и получить ответ). В самой тривиальной реализации этот сценарий может выглядеть как простой выбор задачи из списка. С применением такого подхода в промышленности можно столкнуться уже сегодня. Позвонив в банк или авиакомпанию можно часто услышать робота, который предложит нажать разные кнопки в зависимости от цели звонка ("Для проверки балланса нажмите 1, для уточнения статуса заявки нажмите 2" и.т.п.). Этот подход хорош тем, что не требует от системы никакой интеллектуальности и работает очень надежно. Однако занимает много пользовательского времени и зачастую нервирует. В идеальном случае мы хотели бы получив запрос в виде предложения на натуральном языке, например "Какая погода сейчас на улице?" сразу распознать намерение пользователя.  
Это одна из подзадач в построении диалоговых систем, на которой хотелось бы сконцентрировать наше внимание в этой работе. 
Данная задача является довольно актуальной и стоит уже давно. Так что для ее решения было предложенно множество методик. Подобнее они будут рассмотрены в разделе "Обзор литературы". Большинство методов ориентированно на работу с английским языком. В основном потому, что для английского собранно наиболее большое колличество данных. Кроме того английский просто считается языком по умолчанию в научной среде.  
В то время как для английского языка достигнуты внушительные результаты, ситуация с другими языками обстоит несколько иначе. Представленные модели в большинстве своем обучены на коллосальном объеме размеченных данных. Таких данных не существует для более редких языков. По этому простое перенесение достигнутых результатов путем обучения идентичной модели на другом языке не представляется возможным.  
Тем не менее, почти для всех мировых языков существуют полные словари. Пользуясь общими знаниями о связи двух языков (словари, параллельные тексты) можно обобщить знания одной модели на другой язык не используя размеченных данных для второго языка совсем (либо используя совсем немного). Данный подход в литературе носит название Transfer Learning.
Целью данной работы будет построение модели для извлечения намерения из предложения на **шведском** языке при помощи переноса знаний накопленных обученной на английском языке моделью. Выработанную методику можно будет использовать для построения моделей приблизительно такой же точности для любого другого языка для которого существует словарь перевода его слов на английский. 

### Постановка задачи

Пусть существует множество комманд на английском языке \\(E\\) и конечное множество намерений \\(K\\)

\\[ 
    K = \{k_1,k_2,...,k_n\}
\\]
Каждой команде из \\(E\\) однозначно соответствует элемент множества \\(K\\). Соответствие обозначим \\(I_e\\)
\\[ 
    I_e : E \to K
\\]
Тренировочные данные состоят из множеств \\(E, K\\) и соответствия \\(I_e\\).  При этом существует так же функци-переводчик \\(T\\), которая каждой команде на английском языке ставит в соответствие команду на шведском языке. Множество комманд на шведском языке обозначим \\(S\\)
\\[ 
    T : E \to S
\\]
Целью данной работы будет получение функции \(I_s : S \to K \) сопоставляющей любой команде на шведском языкее намерение. При этом должны выполняться два условия. 

1.  Намерение должно совпадать с намерением перевода шведской команды на английский язык. 

	\begin{equation} \label{eq:reverse_is}
	\forall s \in S \quad I_s(s) = I_e(T^{-1}(s)) 
	\end{equation}
    \begin{equation} \label{eq:straight_is}
	\forall e \in E \quad I_s(T(e)) = I_e(e)
	\end{equation}

2. Функция \(I_s\) не должна зависеть от функции \(T\)

Второе условие является определяющим для данной задачи. Если бы мы могли использовать функцию \(T\) в \(I_s\) то можно было бы просто определить \(I_s\) как в \eqref{eq:reverse_is} и остановиться на этом.  
Но это невозможно, так как перевод (вычисление \(T^{-1}\)) это слишком дорогостоящая операция. Мы бы хотели получить функцию которая была бы достаточно легковычислимой для использования в мобильных приложениях. Поэтому вместо прямого перевода комманды со шведского языка на английский и последующего применения существующих алгоритмов мы постараемся выделить какие-то ключевые атрибуты комманды на шведском языке и использовать их для распознавания намерения. \par
В силу требования 2 мы едва ли сможем удовлетворить требование 1 полностью. Вместо этого попытаемся построить систему, которая на тренировочных данных сможет максимально часто предсказывать намерения пользователя правильно. В качестве метрики качества предсказаний будем исползовать долю комманд в тестовой выборке, по которой система приняла правильное решение. \par

### Обзор литературы

Задача построения диалоговых систем лежит в области автоматического анализа текстовых данных. Одним из главных вопросов применения нейронных сетей в данной области является эффективное представление слов в памяти компьютера. При анализе текстов мы бы хотели заменять слова на вектора как-то отражающие семантический смысл слова.  
Наиболее распространенный метод получения векторов слов описан в работе \cite{w2v}
В данном подходе обучающий текстовый корпус просматривается окном ширины 2h + 1 слов, и для каждого окна однослойная нейронная сеть предсказывает центральное слово окна w(t) по окружающим w(t + i), i ∈ [−h, h] или
наоборот. Эти архитектуры называются Continuous Bag-of-words и Skipgram соответственно. Минимизируя ошибку предсказания, нейронная сеть строит проекцию слов в векторное пространство заранее определенной размерности. При достижении заданной точности предсказания или определенного
числа эпох, алгоритм генерирует словарь с векторными представлениями для слов из обучающего корпуса.

\begin{figure}[h]
\caption{Архитектуры нейронных сетей, представленные в \cite{w2v} для окна ширины
h = 5}
\centering
\includegraphics{word2vec.png}
\end{figure}

Данный подход позволяет получить вектора обладающие свойством семантической близости. Мы можем надеяться что слова обладающие схожим смыслом будут находится рядом в построенном векторном пространстве.  
После того как методы описанные в \cite{w2v} показали свою эффективность в ряде задач обработки текстов \cite{LM}. Было разработано и предложенно несколько похожих методов построения векторов слов \cite{elmo}, \cite{glove}

В данный момент большинство методик обработки естественного языка так или иначе использует вектора слов. 

В нашей работе мы использовали дополненную реализацию оригинального word to vec "fasttext" \cite{fasttext}. В отличие от оригинальной архитектуры этот подход помимо слов контекста использует части слов для обучения, что позволяет предсказывать вектора слов для слов отсутствующих в тренировочной коллекции. 

Для работы с последовательностями слов (предложениями) часто применяются рекурентные нейронные сети описанные в статьях \cite{rnn} \cite{rnn2}. Воизбежание проблемы затухающих градиентов при обучении, используют LSTM архитектуру \cite{lstm}.

В статье Attention is all you need \cite{attention} группа исследователей из Google описывает принципиально новый подход к обработке последовательной текстовой информации и в частности к переводам. Вместо классической архитектуры рекурентных нейронных сетей с использованием LSTM или GRU модулей автор испозьзует так называемый механизм внимания, Который позволяет более качественно представлять информацию содержащуюся в предложениях на этапе кодирования. Такую сеть так же называют "Трансформер" из за гибкости внутренней структуры, позволяющей получать разную информацию о кодируемом предложении в зависимости от запроса. Многие современные автоматические переводчики пользуются этой технологией. В нашей работе мы пользовались готовой системой автоматического перевода от  Яндекс. Примерное описание механизмов работы их переводчика доступно в статье \cite{ytranslate}

Идея трансформер сетей развивается в статье \cite{bert}. Авторы предлагают тренировать многослойную модель из трансформер модулей на задаче определения связности предложений и предсказания пропущенного слова. Полученная модель показывает исключительные результаты после дообучения на ряде конкретных задач. 

Задача предсказания намерения из фиксированного множества может быть сформулированная как задача классификации предложений. Интересный подход к этой задаче с использованием сверточных сетей предложен в статье \cite{deepPavlovCNN}.
### Обработка данных

В нашей работе в качестве тренировочных и тестовых данных мы использовали датасет собранный компанией SNIPS \cite{snips}. 
Данные включают в себя более 13000 запросов пользователей на английском языке. Каждый запрос относится к одной из семи категорий по намерению пользователя. 
 
Представленные намерения:
\begin{itemize}
  \item Get weather (Посмотреть погоду - 2000 записей)
  \item Play music (Включить музыку - 2000 записей)
  \item Book restaurant (Забронировать ресторан - 1973 записей)
  \item Search creative work (Посик произведений - 1954 записей)
  \item Add to playlist (Добавить в плейлист - 1942 записей) 
  \item Rate book (Поставить оценку книге - 1956 записей)
  \item Search movie schedule (Расписание сеансов кино - 1959 записей)
\end{itemize}

Данные предоставленны компанией SNIPS по лицензии Creative Commons Zero v1.0 Universal и доступны для скачивания по ссылке \url{https://github.com/snipsco/nlu-benchmark}

\begin{table}[H]
\caption{Примеры запросов из датасета SNIPS}
\label{tabular:timesandtenses}
\begin{center}
\begin{tabular}{ccc}
\textbf{Категория} & \textbf{Пример} \\
Get weather & What is the forecast at 12 am in Sudan. \\
Play music  & Play some 1954 songs on my Itunes. \\
Book restaurant  & What is the forecast at 12 am in Sudan. \\
Search creative work  & Find me the Lace and Whiskey soundtrack. \\
Add to playlist  & Add this artist to spring music. \\
Rate book  & give this textbook a 5 out of 6 rating. \\
Search movie schedule  & Where is Road to the Stage playing. \\
\end{tabular}
\end{center}
\end{table}
Для подготовки тренировочных и тестовых данных на шведском языке мы использовали API сервиса Яндекс Переводчик \footnote{\url{https://translate.yandex.ru/developers}}. 

### Алгоритм
### Результаты
### Выводы
### Заключение

