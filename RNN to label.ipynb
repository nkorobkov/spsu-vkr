{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import fastText\n",
    "from utils import *\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_en = np.load('data/snips_processed/USE-en.npy')\n",
    "use_en = np.squeeze(use_en, axis=1)\n",
    "labs = np.load('data/snips_processed/labs.npy')\n",
    "\n",
    "\n",
    "dataset, lab2id, id2lab =import_data('data/snips_processed/snips.csv')\n",
    "sents = dataset[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_model = fastText.load_model('data/cc.sv.300.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_m(sentence, model, max_len):\n",
    "    result = []\n",
    "    words = ['sossos'] + sentence.split() + ['eoseos']\n",
    "    \n",
    "    for word in words:\n",
    "        result.append(model.get_word_vector(word))\n",
    "    \n",
    "\n",
    "    if len(words) < max_len:\n",
    "        result.extend([np.zeros(300)] * (max_len  -  len(words)))\n",
    "    return np.array(result)\n",
    "    \n",
    "    \n",
    "def prepare_sentences(sents, preprocess=False):       \n",
    "    sents = pre_process_text(sents)  if preprocess else sents\n",
    "    lens = list(map(lambda x: x.count(' ') + 3, sents))\n",
    "    max_len = max(lens)\n",
    "    m = np.stack(list(map(lambda x:sentence_m(x, sv_model, max_len), sents)))\n",
    "    return m, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_lens = prepare_sentences(sents, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, max_s_len , emb_dim = 300, out_size = 512):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        #(batch, sent_len, emb_dim)\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_size =out_size\n",
    "        self.max_s_len = max_s_len\n",
    "        self.kernel_sizes = [2,3,5]\n",
    "        self.cnn_chan  = 128\n",
    "        self.lstm_hid  = 256\n",
    "        \n",
    "        self.drop = nn.Dropout(0.35)\n",
    "\n",
    "        self.max_pool_kernel_size = [(self.max_s_len - x + 1, 1) for x in self.kernel_sizes]\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.cnn_chan, kernel_size=(self.kernel_sizes[0], self.emb_dim), )\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=self.cnn_chan, kernel_size=(self.kernel_sizes[1], self.emb_dim), )\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=self.cnn_chan, kernel_size=(self.kernel_sizes[2], self.emb_dim), )\n",
    "        \n",
    "        #dont add dropout  to last layer since there is only one layer\n",
    "        self.lstm = nn.GRU(input_size = self.emb_dim, hidden_size = self.lstm_hid,\n",
    "                         batch_first=True, bidirectional=True)\n",
    "    \n",
    "    \n",
    "        self.lin = nn.Linear(self.lstm_hid*2 + self.cnn_chan * 3, out_size)\n",
    "        self.out = nn.LogSoftmax(1)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, lens):\n",
    "        \n",
    "        # add chanels dimention:\n",
    "        xc = x.unsqueeze(1)\n",
    "        \n",
    "        x1 = self.conv1(xc)\n",
    "        x1 = F.max_pool2d(F.relu(x1), self.max_pool_kernel_size[0])\n",
    "        x1 = x1.squeeze(3).squeeze(2)\n",
    "        \n",
    "        x2 = self.conv1(xc)\n",
    "        x2 = F.max_pool2d(F.relu(x2), self.max_pool_kernel_size[1])\n",
    "        x2 = x2.squeeze(3).squeeze(2)\n",
    "\n",
    "        x3 = self.conv1(xc)\n",
    "        x3 = F.max_pool2d(F.relu(x3), self.max_pool_kernel_size[2])\n",
    "        x3 = x3.squeeze(3).squeeze(2)\n",
    "\n",
    "        ps = nn.utils.rnn.pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        _, (h) = self.lstm(ps)\n",
    "        lstm_out = torch.cat((h[1],h[0]), dim =1)\n",
    "\n",
    "        z = torch.cat((x1,x2,x3, lstm_out), dim=1)\n",
    "        \n",
    "        z = self.drop(z)\n",
    "        z = self.lin(z)\n",
    "        \n",
    "        return self.out(z)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, vectors, lens, labels):\n",
    "    model.zero_grad()\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    # vectors = torch.tensor(vectors).float()\n",
    "    # labels = torch.tensor(labels)\n",
    "\n",
    "    model_out = model.forward(vectors, lens)\n",
    "    \n",
    "    loss += criterion(model_out, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / len(labels)\n",
    "\n",
    "def evaluate(model, vectors, lens,labels,  criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        #vectors = torch.tensor(vectors).float()\n",
    "        #labels = torch.tensor(labels)\n",
    "    \n",
    "        model_out = model.forward(vectors, lens)\n",
    "        right = 0\n",
    "        \n",
    "        for i  in range(len(model_out)):\n",
    "            k, v = model_out[i].topk(1)\n",
    "            predicted, true = v.item(), labels[i].item()\n",
    "            if predicted == true:\n",
    "                right +=1\n",
    "\n",
    "                \n",
    "        loss = criterion(model_out, labels)\n",
    "        return loss.item(), right/len(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:10000]\n",
    "test_data = data[10000:]\n",
    "\n",
    "train_out = use_en[:10000]\n",
    "test_out = use_en[10000:]\n",
    "\n",
    "train_lens = data_lens[:10000]\n",
    "test_lens = data_lens[10000:]\n",
    "\n",
    "test_labs = labs[10000:]\n",
    "train_labs = labs[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNN(max_s_len=train_data.shape[1], out_size=7)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "vectors = torch.tensor(train_data).float()\n",
    "labels = torch.tensor(train_labs)\n",
    "\n",
    "tvectors = torch.tensor(test_data).float()\n",
    "tlabels = torch.tensor(test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    25 sec. train loss: 0.0001426, eval loss: 1.3406, acc = 0.6361\n",
      "# 20,  2706 sec. train loss: 0.0000471, eval loss: 0.4468, acc = 0.8528\n",
      "# 40,  8971 sec. train loss: 0.0000192, eval loss: 0.2122, acc = 0.9279\n",
      "# 60,  9403 sec. train loss: 0.0000119, eval loss: 0.1560, acc = 0.9487\n",
      "# 80,  9842 sec. train loss: 0.0000084, eval loss: 0.1378, acc = 0.9567\n",
      "#100, 10279 sec. train loss: 0.0000078, eval loss: 0.1289, acc = 0.9585\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d4bc118708e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print('#{:3d}, {:5d} sec.'.format(i, int(time.time()-t)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-44f1ff49ee11>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, vectors, lens, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# labels = torch.tensor(labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-4d2e2460f66d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lens)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool_kernel_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/virtualenvs/main/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/virtualenvs/main/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for i in range(400):\n",
    "    loss = train(net, criterion, optimizer, vectors, train_lens, labels)\n",
    "    if True and not i% 20:\n",
    "        #print('#{:3d}, {:5d} sec.'.format(i, int(time.time()-t)))\n",
    "        eval_loss, acc = evaluate(net, tvectors, test_lens, tlabels, criterion)\n",
    "        print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.4f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
