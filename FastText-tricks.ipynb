{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# use this library https://github.com/facebookresearch/fastText/tree/master/python\n",
    "import fastText\n",
    "\n",
    "import contractions\n",
    "import unicodedata\n",
    "import re\n",
    "from collections import defaultdict,Counter\n",
    "from utils import *\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset, lab2id, id2lab =import_data('data/snips_processed/snipsf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sv_model = fastText.load_model('data/cc.sv.300.bin')\n",
    "#en_model = fastText.load_model('data/cc.en.300.bin')\n",
    "fi_model = fastText.load_model('data/cc.fi.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vec(sentence, model, stats):\n",
    "    result = np.zeros((1, 300))\n",
    "    \n",
    "    norm = 0\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        \n",
    "        wv =  model.get_word_vector(word)\n",
    "        word_util = stats[word].get('u', 0)\n",
    "        result += wv*word_util\n",
    "        norm += word_util\n",
    "    return result/norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence_vecs(data, lang = 'en', preprocess=False):\n",
    "\n",
    "    if lang == 'en':\n",
    "        model = en_model\n",
    "        slab = 1\n",
    "    elif lang == 'sv':\n",
    "        model = sv_model\n",
    "        slab = 2\n",
    "    elif lang == 'fi':\n",
    "        model = fi_model\n",
    "        slab = 3\n",
    "    else:\n",
    "        raise RuntimeError('lang is not supported')\n",
    "    \n",
    "    vectors = []\n",
    "    \n",
    "    sents = pre_process_text(data[:, slab])  if preprocess else data[:, slab]\n",
    "    \n",
    "    stats, utils = compute_per_word_label(data[:,0], sents)\n",
    "\n",
    "    vecs = list(map(lambda x:sentence_vec(x, model, stats), sents))\n",
    "        \n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vecs_en_uw = prepare_sentence_vecs(dataset, lang='en', preprocess=True)\n",
    "#print('en-done')\n",
    "#vecs_sv_uw = prepare_sentence_vecs(dataset, lang='sv', preprocess=True)\n",
    "#print('sv-done')\n",
    "\n",
    "vecs_fi_uw = prepare_sentence_vecs(dataset, lang='fi', preprocess=True)\n",
    "\n",
    "labs = prepare_labs(dataset[:,0], lab2id)\n",
    "\n",
    "vecs_en = list(np.load('data/snips_processed/FastText-en.npy'))\n",
    "vecs_sv = list(np.load('data/snips_processed/FastText-sv.npy'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train_model(train_vecs, train_labs, test_vecs, test_labs, verbose = False, runs = 4001):\n",
    "    net = Baseline(in_size=train_vecs[0].shape[1])\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    \n",
    "    \n",
    "    tvecs = torch.tensor(train_vecs).float()\n",
    "    tvecst = torch.tensor(test_vecs).float()\n",
    "    tlabs = torch.tensor(train_labs)\n",
    "    tlabst = torch.tensor(test_labs)\n",
    "        \n",
    "    t = time.time()\n",
    "    for i in range(6001):\n",
    "        loss = train(net, criterion, optimizer, tlabs, tvecs)\n",
    "        if verbose and not i% 100:\n",
    "            eval_loss, acc = evaluate(net, tlabst, tvecst, criterion)\n",
    "            print('#{:3d}, {:5d} sec. train loss: {:.7f}, eval loss: {:.4f}, acc = {:.3f}'.format(i, int(time.time() - t), loss, eval_loss, acc))\n",
    "    \n",
    "    eval_loss, acc = evaluate(net, tlabst, tvecst, criterion)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(vecs, labs, folds = 5):\n",
    "    \n",
    "    delims = np.arange(0, len(vecs), len(vecs)//folds)\n",
    "    results = []\n",
    "    t = time.time()\n",
    "    for i in range(folds):\n",
    "        results.append(\n",
    "            full_train_model(vecs[:delims[i]] + vecs[delims[i+1]:],\n",
    "                             labs[:delims[i]] + labs[delims[i+1]:],\n",
    "                             vecs[delims[i] : delims[i+1]],\n",
    "                             labs[delims[i] : delims[i+1]],\n",
    "                                  False, runs = 6001))\n",
    "        print('#{:3d}, {:5d} sec. acc = {:.3f}'.format(i, int(time.time() - t), results[-1]))\n",
    "\n",
    "    return(sum(results)/len(results))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,   179 sec. acc = 0.966\n",
      "#  1,   469 sec. acc = 0.962\n",
      "#  2,  1436 sec. acc = 0.964\n",
      "#  3,  1678 sec. acc = 0.961\n",
      "#  4,  1770 sec. acc = 0.959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9624818577648766"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_en_uw, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    60 sec. acc = 0.940\n",
      "#  1,   124 sec. acc = 0.944\n",
      "#  2,   198 sec. acc = 0.948\n",
      "#  3,   277 sec. acc = 0.941\n",
      "#  4,   347 sec. acc = 0.939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9423802612481857"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_sv_uw, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    61 sec. acc = 0.914\n",
      "#  1,   123 sec. acc = 0.930\n",
      "#  2,   181 sec. acc = 0.919\n",
      "#  3,   246 sec. acc = 0.921\n",
      "#  4,   313 sec. acc = 0.912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9193033381712628"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_en, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    92 sec. acc = 0.942\n",
      "#  1,   184 sec. acc = 0.947\n",
      "#  2,   275 sec. acc = 0.944\n",
      "#  3,   365 sec. acc = 0.943\n",
      "#  4,   420 sec. acc = 0.941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9432510885341074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_fi_uw, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/snips_processed/FastText-uw-fi',np.array(vecs_fi_uw))\n",
    "#np.save('data/snips_processed/FastText-uw-en',np.array(vecs_en_uw))\n",
    "#np.save('data/snips_processed/FastText-uw-sv',np.array(vecs_sv_uw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как написано в статье https://openreview.net/forum?id=SyK00v5xx\n",
    "\n",
    "После получения взвешенной суммы можно отфильтровать составляющую главной компоненты. Но получается что не помогает. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prim_component(vecs):\n",
    "    u, s, v = np.linalg.svd(np.squeeze(np.array(vecs), axis=1), full_matrices=False)\n",
    "    uut = np.array([u[0]]).T @ np.array([u[0]])\n",
    "    new_v = []\n",
    "    for el in vecs:\n",
    "        new_v.append(el - (uut @ el.T).T)\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_en_pcr  = remove_prim_component(vecs_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    65 sec. acc = 0.965\n",
      "#  1,   124 sec. acc = 0.962\n",
      "#  2,   182 sec. acc = 0.964\n",
      "#  3,   242 sec. acc = 0.961\n",
      "#  4,   302 sec. acc = 0.960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9624092888243831"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_en_pcr, labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Переход к пространству расстояний до центроидов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_kmeans(vecs, clusters=50):\n",
    "    kmeans_en = KMeans(n_clusters=clusters).fit(np.squeeze(np.array(vecs), axis=1))\n",
    "    centroids = kmeans_en.cluster_centers_\n",
    "    new_vecs = []\n",
    "    for old_v in vecs:\n",
    "        new_v = np.array([list(map(np.linalg.norm, centroids - old_v))])\n",
    "        new_vecs.append(new_v)\n",
    "        \n",
    "    return new_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_en_kmeans  = transform_to_kmeans(vecs_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    27 sec. acc = 0.731\n",
      "#  1,    50 sec. acc = 0.729\n",
      "#  2,    89 sec. acc = 0.722\n",
      "#  3,   113 sec. acc = 0.746\n",
      "#  4,   139 sec. acc = 0.714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7285195936139333"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_en_kmeans, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_sv_kmeans  = transform_to_kmeans(vecs_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    25 sec. acc = 0.602\n",
      "#  1,    63 sec. acc = 0.613\n",
      "#  2,    98 sec. acc = 0.621\n",
      "#  3,   135 sec. acc = 0.603\n",
      "#  4,   168 sec. acc = 0.621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6121190130624092"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_sv_kmeans, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_en_kmeans100  = transform_to_kmeans(vecs_sv, clusters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0,    44 sec. acc = 0.674\n",
      "#  1,    89 sec. acc = 0.677\n",
      "#  2,   125 sec. acc = 0.689\n",
      "#  3,   157 sec. acc = 0.674\n",
      "#  4,   188 sec. acc = 0.687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6800435413642961"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(vecs_en_kmeans100, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.61104783])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.linalg.norm(vecs_en_uw, axis  = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
